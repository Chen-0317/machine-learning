import os
import torch
import torch.nn.functional as F
import cv2
import numpy as np
from torchvision import transforms, models
from config import *  # åŒ¯å…¥é›†ä¸­è¨­å®š
import argparse

# ============================================================
# å‘½ä»¤åˆ—åƒæ•¸è¨­å®š
# ============================================================
parser = argparse.ArgumentParser(description="Predict Cat vs Dog Images")
parser.add_argument("--image", type=str, help="Path to a single image for prediction")
parser.add_argument("--folder", type=str, help="Path to a folder containing multiple images")
args = parser.parse_args()

# ============================================================
# æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
# ============================================================
if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆï¼š{MODEL_PATH}\nè«‹å…ˆåŸ·è¡Œ train.py è¨“ç·´æ¨¡å‹ã€‚")

# ============================================================
# æ¨¡å‹è¼‰å…¥
# ============================================================
print(f"ğŸ§  è¼‰å…¥æ¨¡å‹ï¼š{MODEL_PATH}")
device = DEVICE

model = models.resnet34(weights=None)
num_ftrs = model.fc.in_features
model.fc = torch.nn.Linear(num_ftrs, NUM_CLASSES)

model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
model = model.to(device)
model.eval()

# ============================================================
# å‰è™•ç† Transformï¼ˆéœ€èˆ‡è¨“ç·´ä¸€è‡´ï¼‰
# ============================================================
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# ============================================================
# å–®å¼µåœ–ç‰‡é æ¸¬å‡½å¼
# ============================================================
def predict_image(img_path):
    if not os.path.exists(img_path):
        print(f"âš ï¸ æ‰¾ä¸åˆ°åœ–ç‰‡ï¼š{img_path}")
        return

    img = cv2.imread(img_path)
    if img is None:
        print(f"âš ï¸ ç„¡æ³•è®€å–åœ–ç‰‡ï¼š{img_path}")
        return

    # è½‰ç°éšâ†’3é€šé“
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)

    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)
        probs = F.softmax(outputs, dim=1)[0].cpu().numpy()

    pred_idx = np.argmax(probs)
    confidence = probs[pred_idx]

    if confidence < THRESHOLD:
        print(f"ğŸŸ¡ åœ–ç‰‡ï¼š{os.path.basename(img_path)} â†’ ç„¡æ³•è¾¨è­˜ï¼ˆä¿¡å¿ƒ {confidence:.2f}ï¼‰")
    else:
        print(f"âœ… åœ–ç‰‡ï¼š{os.path.basename(img_path)} â†’ {CLASS_NAMES[pred_idx]}ï¼ˆä¿¡å¿ƒ {confidence:.2f}ï¼‰")

# ============================================================
# æ‰¹æ¬¡æˆ–å–®å¼µé æ¸¬
# ============================================================
if args.image:
    predict_image(args.image)
elif args.folder:
    image_files = [f for f in os.listdir(args.folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))]
    if not image_files:
        print("âš ï¸ è©²è³‡æ–™å¤¾å…§æ²’æœ‰åœ–ç‰‡ã€‚")
    else:
        for img_name in image_files:
            predict_image(os.path.join(args.folder, img_name))
else:
    print("âš ï¸ è«‹ä½¿ç”¨ --image æˆ– --folder åƒæ•¸æŒ‡å®šè¦é æ¸¬çš„åœ–ç‰‡ã€‚")
